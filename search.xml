<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《Causal Embeddings for Recommendation》笔记]]></title>
    <url>%2F2019%2F02%2F28%2FCausal-Embeddings-for-Recommendation%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[摘要应用中期望使用推荐策略来推荐最适合的结果来改变用户行为，最大化推荐收益，如极大化点击率等。但由于推荐系统改变了用户的行为方式，使得用户的日志行为和原本的用户自然行为有了比较大的差异。简单的在用户日志上训练和评估推荐策略，产生的结果和用户的自然行为产生比较大的误差。论文中提出一种矩阵分解的方法，利用随机曝光的数据，得到了更好的结果。 参考资料Bonner S, Vasile F. Causal embeddings for recommendation[C]//Proceedings of the 12th ACM Conference on Recommender Systems. ACM, 2018: 104-112. 介绍应用的推荐策略向用户推送结果，然后用户点击、浏览的记录行为即用户日志。直接在用户日志上训练、评估推荐策略，除了产生的推荐结果和用户自然行为产生较大误差，也会使得频次高但历史悠久的商品依然被推荐很多。这个我比较深有感触，在实习期间发现，两个月前的内容依然被不断推荐给用户，由于内容本身与明星相关，点击率不会很低，可由于历史悠久点击率也上不去。对于这种比较旧的内容是应该降低推荐的频次，尝试推荐新的内容产生更好的收益。对于新内容缺乏训练数据，这方面就是多臂赌博机问题了。这是由于用户日志行为是被推荐策略改变的行为的偏好，如果能直接在用户的自然行为上进行策略学习，推荐的结果就是最符合用户的偏好。 用户的自然行为可以看作是向用户随机推荐商品产生的用户行为记录。由于随机策略不会改变商品曝光的概率分布（即是商品曝光概率是相同的），因此用户的行为记录能反映真实的偏好。但随机策略产生的收益较低，因为推荐的结果和用户的偏好通常是不吻合的。所以很难应用随机推荐策略产生大量的数据来学习好的推荐策略。 其中，两种策略的对比如下： 应用推荐策略，数据量大，精度高，但改变用户的自然行为。 随机策略，数据量少，精度低，反映用户的自然行为。 论文中采用多任务学习来训练模型，方法之前的证明感觉和方法没什么太大的关联，都是为了证明考虑自然行为的有效性。 对于推荐策略的学习目标是：$$L_{t}=\sum_{\left(i, j, y_{i j}\right) \in S_{t}} l_{i j}^{t}=L\left(U \Theta_{t}, Y_{t}\right)+\Omega\left(\Theta_{t}\right)$$可以看出，通过用户嵌入$U$和物品嵌入$\Theta_t$计算的内积得到用户点击概率，就是简单的FM模型。而对于随机策略的数据也是类似的：$$L_{c}=L\left(U \Theta_{c}, Y_{c}\right)+\Omega\left(\Theta_{c}\right)+\Omega\left(\Theta_{t}-\Theta_{c}\right)$$和之前相比只是物品嵌入$\Theta_c$不同，其中两个物品嵌入之间的联系，用一个超参来控制它们的差异。 在实验里，通过平衡物品间曝光的概率，得到随机策略产生的数据，这部分我是比较的有疑问的。 感想论文中认为只考虑推荐策略结果来训练模型的问题，解释了我一直以来的疑问。通过考虑用户自然行为来提升模型效果，这个概念我觉得是比较有意思的。但方法中简单使用多任务学习，我觉得好像也太简单了点。而且不适用于推广到其它复杂的模型上。]]></content>
      <categories>
        <category>报告</category>
      </categories>
      <tags>
        <tag>推荐</tag>
        <tag>recommendation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯社交广告高校算法大赛总结]]></title>
    <url>%2F2017%2F07%2F08%2F%E8%85%BE%E8%AE%AF%E7%A4%BE%E4%BA%A4%E5%B9%BF%E5%91%8A%E9%AB%98%E6%A0%A1%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[题目描述http://algo.tpai.qq.com/home/home/index.html 成绩决赛第7名 赛题分析 比赛中，我们比较关心的一个问题在于：数据线上线下分布不一致：1、某些app和用户的记录比较少；2、数据的时效性要求较高。这对于特征工程会是一个比较大的要求，在比赛中有许多的特征会使得线上的成绩下降，比如各种差分的特征。 特征工程特征的提取主要有以下几个方面： 基础特征：计数特征、转化率、比例特征等各种基本的特征； 线上的特征：基于当天数据统计的用户行为、app行为的特征； 用户行为挖掘特征：word2vec计算用户行为与历史行为的关联； 特征提取方式有以下几个方面考虑： 基于cv统计、贝叶斯平滑等方法，能够很好的修正线上线下的特征分布不一致的问题； 特征提取主要有基于全局的数据统计以及滑窗的历史统计。 基于全集的数据统计生成的特征：是决赛中主要的特征提取方式，效果比较平稳，而且信息量比较多，但容易会有信息泄露的问题需要通过cv统计来避免，而且难以反映时间变化的信息。 基于滑窗的生成特征：能反映时序上的信息，不会有信息泄露的问题。但是生成的特征数量多，线上线下的分布差异比较大，特征工程方面的工作量比较大。 因此，比赛中我选择了两种生成特征的方式来产生不同的模型进行融合。 特征选择 在初赛阶段，主要有以下三种方式来筛选特征：1、删除线上线下均值差异30%以上的特征；2、通过xgboost计算的特征重要性，删除重要性较低的特征；3、通过wrapper的方式选择特征。通过以上方式能够保证线上线下的特征稳定，但这工作在决赛数据量大的情况下会比较耗时。 在决赛阶段，每加入一部分特征，通过线上的成绩反馈来选择特征的去留。 模型方法 比赛中主要使用stacking 的方式，其中一个模块的示意图如下： 如图所示，模块中使用cv的方法，把数据分成5份来进行训练和预测，这样模型的效果会比单模型的要好些（相当于投票的一种策略）。此外模块中stack3层，每一层使用原有的特征和预测值作为下一个模型的输入，增强模块的精度。模型中使用xgboost和lightgbm。 这种模型的缺点在于，效率是单模型的十几倍，因此需要一种策略来保证效率。这里我使用分而治之的思想，每一次训练使用上一个模块的预测值和当前新提取的特征，作为下一个模块的输入进行训练，不断迭代。这样相当于把所有的特征分成很多部分分开训练，并且在决赛中通过线上成绩反馈来选择特征的去留。最终模型的流水线如下： Component就是模型的一个模块（cv5份和stack3层的模块），每次提取新的特征则加入到新的component中训练。这里流水线中使用了15个模块。 实验中，随着加入的特征越多，模型效果变得更好。模型的效果如下： 模型融合主要有两种融合的方式： 加权融合：当融合的模型效果差异大时，根据线上的成绩人工设定融合的权重； logistic平均：当融合的模型效果差异小时，采用以下公式进行融合：$p=f(\frac{\sum_i f^{-1}(p_i)}{n})$ 除了stacking的模型，同时也考虑全集和滑窗特征上的单模型效果，还有每个component成绩，进行融合： ##赛后总结 个人感觉在模型的stack方面，已经做到了很好的程度，实验的结果表明比单模型的效果要好且鲁棒性更高。但是决赛后期尝试使用ffm算法，但是效果一直不理想，所以只是稍微的加进去原来的模型中进行融合。]]></content>
  </entry>
  <entry>
    <title><![CDATA[腾讯社交广告高校算法大赛心得]]></title>
    <url>%2F2017%2F05%2F21%2F%E8%85%BE%E8%AE%AF%E7%A4%BE%E4%BA%A4%E5%B9%BF%E5%91%8A%E9%AB%98%E6%A0%A1%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[感想写了这东西之后，就感觉自己像是立了个flag一样…… 特征的选择 关于特征选择，其中有两个方面是应该值得关注的。 一方面是特征的重要性，特征的重要性反映的是特征对模型效果的影响程度，理论上重要性越高的特征应该保留下来，而重要性较低的会考虑删除。特征越多，会使得模型越复杂，减少不必要的特征会使得模型更加稳定。其中常用的方法可以考虑xgboost中计算的特征重要性，或者是通过扰乱某个特征值的次序根据模型效果变化来得出。特征重要性计算的方法不少，大家可以再网上查找一下。 另一方面是特征分布是否一致，特征分布主要考虑的是线上和线下的分布差异。由于这次比赛的数据具有时序性，并且很多选手也因为在提取特征时因为信息泄露的原因导致线下成绩提升而线上成绩降低，这些问题都可以通过特征值的分布差异来排除掉，当分布不一致的特征，我们应该优先删除。特征分布差异，简单的可以通过线下和线上特征值的均值、标准差差异来考虑，或者基于其它的统计学的方法。通过特征的重要性和分布综合考虑，应该就可以得到比较理想的特征效果了。 特征生成 关于特征生成，大体上可以分为两个大方向。 一个方向就是俗称的“拍脑袋”，根据个人对于数据观测、题目理解等考虑，得出的一系列规则转化为特征。这样很容易就会产生一系列有用或者无用的特征（比如one-hot、各种的转化率、点击量等特征），其中很多的特征所代表的意义其实是重复的，比如对各种ID做转化率的特征，当特征数量越来越多后，提取这类的特征会显得毫无意义。所以应该多角度的来提取特征，使得特征之间形成互补。 一方面是通过其它模型的结果来生成各种特征，其中能否通过深度学习来产生新的特征？LDA来分析用户和app之间的关系？特征之间不断的组合能否产生比较好的特征？这需要通过对数据的理解，不断的尝试和分析。不过我的并不建议那么快的考虑用其它的模型来生成特征，毕竟这种方法生成的特征有时候并不能很好的理解，并且需要的工作量也比较大，有时候生成的特征也并不一定有效果。 模型的理解 群里面很多的同学知道该用哪个模型，但是并没有理解模型的原理，所以把很多的时间浪费在模型的选取和调参上。事实上，我们应该先对模型有个比较基础的了解，明白模型以及各个参数的原理，这样才能指引我们如果去生成模型适合使用的特征以及怎样去调参。比如，我选取的模型是xgboost，基本上我是没怎么使用one-hot的特征。 对于刚开始比赛来讲，模型应该是简单点比较好，这样主要为了方便特征的生成和选择。当特征方面的工作做到一定的程度上，则可以考虑更复杂的模型来提高效果了。至于模型融合等方面的资料，可以参考网上历来各种比赛分享的资料了。 建议 参加比赛的时候，很多时候选手会因为效果不好等各种原因难免产生比较浮躁和消极的情绪。但我觉得，参加比赛来讲，最重要的是在比赛中有所收获并且提升自己，最直接的方法就是多想多做，而不是光想不做。毕竟比赛的竞争是比较激烈的，获奖的名额比例也不高。或许最后什么名次也没拿到，但是通过不断的提升自己或许以后工作可以升职加薪呢，而这样算下来的钱应该比一个比赛的奖金要多吧。]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>心得</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机场停机位资源分配优化]]></title>
    <url>%2F2017%2F01%2F01%2F%E6%9C%BA%E5%9C%BA%E5%81%9C%E6%9C%BA%E4%BD%8D%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[题目描述https://tianchi.shuju.aliyun.com/outsource/offer/projectdetails.htm?spm=5176.8199929.0.0.nPvIru&amp;id=3092机场每天都有大量的航班起降，每个航班降落以后都会分配到一个指定的机位进行保障，保障结束以后再离开进行下一航段。为了保障每个航班都有相应的机位，机场会提前安排好第二天的所有飞机机位资源。 成绩复赛：得分14.40，排行榜第一名；决赛：第一名 总体思路1、 求解初始解：使用贪心算法快速得到一个可行解2、 优化解：使用优化算法对初始解进行优化，我们采用的优化算法是破坏与重建算法 贪心算法按时间顺序遍历每个航班，对每个航班执行下面操作：尝试安排到其可安排的机位中，若当前机位能安排（能安排代表满足各种约束）就直接安排，若没有机位能安排当前航班，则当前航班不安排。只需不到1秒的时间，生成了13.28的初始可行解。 破坏与重建算法步骤一、对一个已知的初始解，破坏掉一些已经被安排的航班，即一个破坏过程；步骤二、对剩下已经安排的航班其机位保持不变，将当前所有未安排的航班使用线性规划模型求解当前情况下的最优解，即一个重建过程；步骤三、重复此破坏与重建过程，持续对解进行优化，直到满足一个停止条件。 算法评价：此算法通过破坏可以打破局部约束，使其可以达到一个更优的解；通过线性规划模型进行重建，使其可以得到当前情况下的最优解，这个解不会比初始解差；由于已分配机位的航班在时间上是均匀分布，影响剩下航班的分配，因此未分配的航班虽多但重建效率很快。 线性规划模型变量二进制变量$g_{ij}∈G$表示航班分配机位的情况：$$g_{ij}=\begin{cases}1&amp; \text{航班i分配到机位j}\\0&amp; \text{航班i没有分配到机位j} \end{cases}$$滑道冲突的计算与机位的入滑道和出滑道有关，但和具体机位是无关的，具体不同滑道可以表示为$p_k∈P$;二进制变量$d_{ik}∈D$表示航班滑道冲突的情况：$$d_{ik}∈\begin{cases}1&amp;\text{航班i的滑道为$p_k$，且和其它航班滑道冲突}\\0&amp;\text{航班i的滑道非$p_k$，或和其它航班没有滑道冲突}\end{cases}$$每个航班的旅客人数用$h_i∈H$来表示，总的旅客人数为$h_sum=\sum_ih_i $；定义总的航班数量为$n$，总的机位数量为$m$； 目标函数$$F(G,P,D)=max\sum_{i,j}10×\frac{g_{ij}}{n}+3×\frac{g_{ij}×1\{机位j是近机位\}}{n}+3×g_{ij}×1\{机位j是近机位\}×\frac{h_i}{h_{sum}} -1×\frac{g_{ij}×1\{机位j是临时机位\}}{n}-\sum_{i,k}1×\frac{d_{ik}}{n}$$ 约束条件 对于初始固定的航班添加约束：$$∀i,j航班i预先分配到机位j\longrightarrow g_{ij}=0$$$$∀i航班i不分配机位\longrightarrow∀j,g_{ij}=0$$ 保证每个航班只会分配一个机位：$$∀i\longrightarrow\sum_jg_{ij} ≤1$$ 保证航班只能分配到可以分配的机位：$$∀i,j航班i不能分配到机位j\longrightarrow g_{ij}=0$$ 保证在同一个机位上的航班满足十分钟约束：$$∀i_1,i_2,j且航班i_1 和航班i_2 不满足十分钟约束\longrightarrow g_{i_1j }+g_{i_2 j}≤1$$ 保证在机位发生重合时也满足十分钟约束：$$∀i_1,i_2,j_1,j_2 且机位j_1 和机位j_2 重合，航班i_1 和航班i_2 不满足十分钟约束\longrightarrow g_{i_1j_1}+g_{i_2 j_2}≤1$$ 保证分配方案满足阻挡的约束：$$∀i_1,i_2,j_1,j_2 且航班i_1 在机位j_1 阻挡航班i_2 进入机位j_2\longrightarrow g_{i_1j_1 }+g_{i_2 j_2}≤1$$ 滑道冲突约束，航班的滑道冲突和分配的机位相关：$$∀i,k\longrightarrow \sum_jg_{ij}×1\{机位j的滑道为p_k \} ≥d_{ik}$$ 滑道冲突约束，当航班分配了机位且存在滑道冲突时，$d_ik$为1,$c$是一个很大的常数：$$∀i,k\longrightarrow \sum_jg_{ij}×1\{机位j的滑道为p_k \} +\sum_{i_1≠i,j_1}\frac{g_{i_1j_1}×1\{航班i在滑道k与航班i_1在滑道j_1滑道冲突\}}{c}≤d_{ik}$$模型优化 机位冲突优化：对于上面的第4个约束，同一机位的航班满足10分钟约束，以及第5个约束，机位发生重合时满足十分钟约束，可以换一种思路去考虑，换成:任何一个位置在任何一个时刻最多只有一架飞机，一个飞机占用这个位置的时间为$[in\_time,out\_time+10)$,也既是：$$∀i_1,i_2,…,i_n,j_1,j_2,…,j_m 且航班i_1 到航班i_n 包含同一个时刻，机位j_1 到机位j_n 包含同一个位置\longrightarrow \sum_j\sum_ig_{ij} ≤1$$进行这样的优化后，将很多的单独的约束合并为一个约束了，模型占用的内存减少了很多，数据中独立的时刻只有1800多个。 滑道冲突优化：对于滑道冲突的约束计算，假如是通过枚举两个航班和其分配的两个机位来判断冲突，时间复杂度为$O(n^2 m^2)$，这样的计算造成运行效率低和内存消耗大。在我们的方法中，滑道约束8的计算只需要枚举两个航班以及对应的滑道即可，滑道的数量远小于机位的数量，极大的提高了运行效率以及降低内存消耗。 破坏方式不同的破坏方式，打破局部约束的能力不一样，所以我们制定了三种基本的破坏方式： 随机航班破坏：随机选取一些航班进行破坏 随机机位破坏：随机选取一些机位，对机位下的航班进行破坏 随机时间破坏：随机选取一个时间段，对这个时间段上的航班进行破坏这三种破坏方式，在破坏相同比例航班的基础上，各自的效果各不相同，我们从重建速度，收敛性两个方面进行比较发现： type 重建速度 收敛 航班破坏 快 中 机位破坏 中 快 时间破坏 慢 慢 在实际使用中，我们主要会采取航班破坏和机位破坏，我们最后的程序中，可以根据自己的实际情况，制定不同的破坏与重建策略。 算法效果研究我们使用机位破坏，每次破坏1/15的机位，迭代了10000次，运行了6个小时，每次大约2.2秒，最后结果到了14.38，下面是运行结果图： 可以看到前期收敛是非常快的，迭代500次，就到达了14.3，大约用时20分钟。不过后面的收敛就非常的缓慢了。 当加大破坏比例后，其收敛能够加快，这里没有数据了，这是我们多次实践的经验结果，具体的详细研究还需要很多的时间。 在对算法的各种性质进行深入实验研究后，可以根据各种不同破坏方式下破坏不同比例的性质的不同，制定最优策略，以达到更快的得到更好的解的目的，目前的策略只是一个感性的策略，根据的是经验。 最优结果说明目前的最优解可以说是我们在进行实验过程中得到的解，我们曾经想到的各种优化方案，都曾经应用到了产生这个解的过程中。还有我们在优化的过程中也是断断续续的跑的，白天要上班或上课，电脑不能跑，到晚上才能跑，所以具体目前得到这个解跑了多久，我们也是不清楚的。 现在要复现这个解也是可以复现，按照现在的算法，只要设置对相应的破坏与重建策略，肯定可以到达现在的解，只是时间问题，因为越到后面收敛是越来越慢的，其实到14.399我们只花了一个晚上了时间，但是到现在的14.4008花了好多个晚上。 比赛总结在比赛的过程中也不是一帆风顺的，前期的工作也尝试过各种不同的方法： 数据规模增大，尝试过对航班分块处理提高算法的效率； 采用对时间的滑窗来对跑线性规划，得到14.25； 用禁忌搜索来优化解，得到14.27； 正是比赛中对各种方法的尝试逐渐增加了对问题、模型的理解，最终得到了一个线性规划与破坏重建结合的算法。比赛收获良多，我们也享受比赛过程中不断进步的喜悦。]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>停机位</tag>
        <tag>线性规划</tag>
        <tag>破坏与重建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读报告 DCM BANDITS: LEARNING TO RANK WITH MULTIPLE CLICKS]]></title>
    <url>%2F2016%2F11%2F20%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A-DCM-BANDITS-LEARNING-TO-RANK-WITH-MULTIPLE-CLICKS%2F</url>
    <content type="text"><![CDATA[摘要 当用户在搜索引擎上查询感兴趣的条目时，通常得到一个包含相关网页链接的列表。用户从第一个网页链接开始，浏览所有的感兴趣的链接并点击，直至得到想要的结果或者是最后一个链接为止。这种用户浏览行为称为dependent click model（DCM）。论文通过最大化推荐的网页链接推荐满意度，向用户推荐最合适的网页链接。在此报告中，先介绍与论文相关的多臂赌博机问题（multi-armed bandit problem）。然后介绍论文作者在2015年发表的相关论文《Cascading Bandits: Learning to Ranking the Cascade Model》，论文与DCM是类似的。最后是DCM的介绍。 参考资料 https://zhuanlan.zhihu.com/p/21388070 专治选择困难症——bandit算法 http://banditalgs.com/2016/09/18/the-upper-confidence-bound-algorithm/ The Upper Confidence Bound Algorithm Kveton B, Szepesvari C, Wen Z, et al. Cascading Bandits: Learning to Rank in the Cascade Model[C]// ICML. 2015:767-776. Katariya S, Kveton B, Szepesvári C, et al. DCM Bandits: Learning to Rank with Multiple Clicks[J]. 2016. 介绍 搜素引擎通常把推荐的网页链接进行排序，按照相关度来进行排序，最相关的网页放在最前面方便用户浏览。在推荐中往往会考虑用户点击的数据，比如cascade mode（Craswell et al., 2008）是网页搜索中最流行的用户行为模型之一。在2015年，本论文的作者曾提出在线的遗憾优化学习算法（regret-optimal online learning algorithms），此级联模型的主要限制在于不能学习多次点击的行为。 在论文中作者提出一个在线学习的算法DCM来学习用户多次点击的问题。在每一个时刻t，推荐给用户一个包含K个网页链接的列表，用户从最开始的链接浏览至最后一个链接，当用户找到感兴趣的链接时会点击链接并且浏览网页，然后可能会离开搜索的界面或者继续浏览下一个链接。当用户离开搜索的界面时，DCM会判断用户是否已经得到其想要的信息：如果用户得到想要的结果离开搜索界面，DCM会得到奖励1；如果用户浏览所有的链接并得不到满意的结果，DCM得到奖励0。DCM的目标在于最大化总的奖励，或者说最小化累积遗憾（推荐的K个网页链接和最优的推荐结果间的差异累积）。本论文中的一个挑战是用户是否得到满意结果是未知的。 在此阅读报告中，着重介绍论文的思想和做法，对于公式的推导过程不做详细的介绍。 多臂赌博机 多臂赌博机问题（multi-armed bandit problem），与平常生活中遇到各式各样的选择问题是息息相关的。比如：去哪里上大学、选择什么专业、中午吃什么等。为此解决这问题需要进行有策略的进行选择，而这就是bandit算法。其解决的问题如下： 一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么想最大化收益该怎么整？这就是多臂赌博机问题。怎么解决这个问题呢？最好的办法是去试一试，而这个试一试也不是盲目地试，而是有策略地试，越快越好，这些策略就是bandit算法。 多臂赌博机问题和很多问题之间是有联系的：1. 假设一个用户对不同类别的内容感兴趣程度不同，那么我们的推荐系统初次见到这个用户时，怎么快速地知道他对每类内容的感兴趣程度？这就是推荐系统的冷启动；2. 假设我们有若干广告库存，怎么知道该给每个用户展示哪个广告，从而获得最大的点击收益？是每次都挑效果最好那个么？那么新广告如何才有出头之日？ 3. 我们的算法工程师又想出了新的模型，有没有比A/B test更快的方法知道它和旧模型相比谁更靠谱？以下本文主要介绍解决此问题的UCB算法。 问题描述 假设有K个老虎机排列在面前，每一次我们可以选择一个老虎机来按并且获得奖励。但老虎机的选择有两个问题：是应该选择过去回报率高的老虎机，还是选择过去回报率较低但是有潜力的老虎机呢？对此，我们可以假设K个老虎机的奖励独立服从一个概率分布，记录每一轮中老虎机的奖励信息，根据历史信息选择奖励最高的老虎机。在多臂赌博机中，把老虎机称之为臂。 UCB算法 这个算法被认为是乐观面对不确定性：首先每一轮猜测各个臂可能给出的奖励，然后选择奖励最高的臂，如果实际获得的奖励少则减少臂的奖励估计，减少对臂的选择；否则提高臂的奖励估计，增加对臂的选择。里面对臂的奖励估计，则是建立一个指数，通过动态的调整指数参数来对臂的奖励估计。 所以需要一个定义策略好坏的指标——累积遗憾：一个策略A和一个动作集{K}，在T时间后的累积遗憾是策略A的期望奖励和最佳臂的期望奖励之差。 定义策略的奖励为$f(A)$，则最优臂为$A^{\ast}=arg \max \limits_{A\in{K}}⁡f(A)$，所以策略A的累积遗憾$R_T(A)=f_T(A^{*})-f_T(A)$，表示该策略与收益期望最大的臂之间的收益差异。所以一个好的策略应该是最小化：$$R(n)=E\left[\sum_{i=1}^n\left[R_t (A_t)\right]\right ]$$ 定理：假设$X_1，X_2，…，X_n$相互独立且服从1-次高斯分布（方差为1、均值为0），$u ̂=\sum_{t=1}^n X_t/n$，可以得到$P(u ̂≥ε)≤exp⁡(-\frac{nε^2}{2})$。 可以写作：$P(u ̂≥\sqrt{\frac{2}{n} log⁡(\frac{1}{δ}))}≤δ$。 所以，对于某个老虎机的估计，可能的形式为：$\hat{u}_i (t-1)+\sqrt{\frac{2}{T_i (t-1)} log⁡(\frac{1}{δ})}$。 δ的选择不同产生不同的算法，当δ越小，策略的选择越乐观（因为指数变得更大）。UCB算法的具体算法如下：取δ=1/t，t是试验的总次数 对每个臂先试一次观察收益情况； 以后每次选择指数最大的臂$\hat{u}_i (t-1)+\sqrt{2/(T_i (t-1)) log⁡(t)}$。 UCB算法的累积期望遗憾是$O(logN)$，最坏情况下累积遗憾不超过$O(\sqrt{KNlogN})$。 Cascading Bandits: Learning to Ranking the Cascade Model 此论文是阅读论文的作者2015年写的，相当于是一个简化版本。 对于用户搜索的条目，搜索引擎返回推荐的K个网页链接，通常K个网页链接是按照相关性进行排序的。用户通常从第一个网页链接浏览到最后一个链接，然后选择最感兴趣的链接进行点击浏览。基于这种用户行为，论文中为了解决搜索引擎中的推荐问题，提出了两个模型：CascadeUCB1和CascadeKL-UCB。两个模型的差异在于置信上限的计算不同。 而且论文中的设定的用户行为模式与现实具有差异的，所以模型不能解决多次点击的行为。 用户行为模式 用户的行为模式如下图所示： 算法 假设总共有n个网页链接，每次向用户推荐K个链接。在第t步得到的奖励认为是推荐的K个网页至少有一个被点击的概率：$$f(A,w)=1-\prod_{k=1}^K(1-w(a_k ))$$ 其中$A=(a_1,…,a_K)$和$w∈[0,1]^E$。 所以累积遗憾函数的计算为$R(A_t,w_t )=f(A^{\ast},w_t )-f(A_t,w_t)$，$A^{\ast}=arg\max \limits_{A∈∏_K(E)}⁡f(A,\overline w)$为理想的网页。 具体的算法步骤如图所示，思想是和多臂赌博机的类似的： $w_0\sim P$： $w_t (e)∈{0,1}$表示用户在时间t对链接e的偏好程度。这个偏好是随机的并且服从伯努利分布（用户感兴趣的链接均值为$p$，不感兴趣的链接均值为$p-\Delta$）； $∀e∈E:T_0 (e)←1$：相当于每个链接首先推荐一遍并被浏览； $∀e∈E:w ̂_1 (e)←1$：每个链接预设浏览了一次并被点击； Compute UCBs：计算每个链接的置信上限； $A_t←(a_1^t……a_K^t)$：选取置信上限最大的K个网页链接进行推荐； $C_t∈{1,…,K,∞}$：表示用户浏览的终止位置，当C_t≤K表示用户找到感兴趣的链接，当C_t=∞表示用户浏览了所有的链接没有找到感兴趣的； $T_t (e)←T_{t-1} (e)+1$：表示链接被浏览的次数加一； $w ̂_{T_t (e) } (e)←⋯$：更新浏览过的链接被点击的次数。 与原先的多臂赌博机问题相比，可以看出计算过程是相似的。每一次像用户推荐K个链接，用户浏览了前$C_t≤K$个链接，并且点击了第$C_t$个链接。可以把每个链接看做是一个赌博机，按照置信上限从大到小向用户逐个推荐链接，并且得到一个收益（用户满不满意），而${C_t+1,…,K}$的链接没有进行试验。由此看来，与原先多臂赌博机问题的差异在于UCBs的计算。 CascadeUCB1算法中：$U_t (e)=\hat{w}_{T_{t-1}(e) ) } (e)+\sqrt{\frac{1.5}{T_{t-1}(e) } log⁡(t-1)}$，与多臂赌博机相比只是系数上的差异；CascadeKL-UCB算法中：$U_t (e)=\max⁡\left\{q\in\left[\hat{w}_{T_{t-1}(e)} (e),1\right]:T_{t-1} (e) D_{KL} \left(\hat{w}_{T_{t-1}(e) } \left(e\right)||q\right)\leq logt+3loglogt\right\}$，其中$D_{KL}(p||q)$是两个服从均值为p和q的伯努利分布变量的KL散度，这里是找一个最大的置信上限满足和观测的均值差异在一个区间内。 DCM Bandits: Learning to Rank with Multiple Clicks 上篇论文中，用户的行为假定只点击一个最吸引他的网页。而在实际情况中，用户往往是点击多个感兴趣的页面，当浏览到需要的网页或者不存在感兴趣的网页才终止浏览的行为。论文中假设每个网页对用户的吸引概率是独立的，并且用户在浏览网页后有个终止的概率表示获取到需要的网页。用户依次浏览推荐的K个网页，用户会点击吸引他的网页，当用户点击网页浏览后如果获取到需要的信息则终止浏览，否则继续浏览下一个网页。为此论文中提出了dcmKL-UCB模型。 用户行为模式 与上一个模型相比，用户会点击多个链接，并且在每一个链接中有一定的概率离开。 用户行为模式如下图所示： 算法 论文中新增添一个只和位置k相关的终止概率，表示当用户在浏览第k个链接后终止继续浏览的概率。当存在一个网页链接是吸引用户的，可以看作收益为1，即$w(e)=1$且$v(k)=1$。所以在第t步得到的奖励认为是推荐的K个网页至少有一个满足用户的需求的概率$$f(A,w,v)=1-\prod_{k=1}^K\left(1-v(k)w(a_k )\right)$$ 实验算法中预设参数： 总网页链接数L； 用户感兴趣的网页链接数K，假设编号为0——K-1； 用户感兴趣的网页，吸引概率p=0.2； 用户不感兴趣的网页与感兴趣的网页之间的吸引用户概率的gap为∆，所以不感兴趣的网页吸引用户的概率为p-∆； 每个位置的终止概率为γ=0.8。 总的迭代次数n=10^5； 每组实验做20次，取均值作为实验结果。 实验结果可以得出： 期望累积遗憾随着K的增大而减少； 期望累积遗憾随着L的增大而变大； 期望累积遗憾随着∆的减少而变大。]]></content>
      <categories>
        <category>报告</category>
      </categories>
      <tags>
        <tag>多臂赌博机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟-需求预测与分仓规划]]></title>
    <url>%2F2016%2F09%2F27%2F%E8%8F%9C%E9%B8%9F-%E9%9C%80%E6%B1%82%E9%A2%84%E6%B5%8B%E4%B8%8E%E5%88%86%E4%BB%93%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[题目描述：https://tianchi.shuju.aliyun.com/competition/introduction.htm?spm=5176.100068.5678.1.ZBYlCN&amp;raceId=231530高质量的商品需求预测是供应链管理的基础和核心功能。本赛题以历史一年海量买家和卖家的数据为依据，要求参赛者预测某商品在未来二周全国和区域性需求量。 基本流程： 和其他机器学习比赛的思路大致是一样的：数据按照分仓和全国分开处理，划分时间窗口提取特征，跑模型，模型融合等，可能这比赛中可以添加规则来提高成绩。 在这里，我主要讲的是比赛中的尝试，与以前不一样的是改变模型求解的损失函数使得更加符合本题。 损失函数分析： 在赛题中，成本的计算受两个参数控制：补多成本和补少成本。当预测库存比实际库存少时，成本总和加上补少成本×库存之差；当预测库存比实际库存多时，成本总和加上补多成本×库存之差。因此补少成本和补多成本对于目标函数有着重大的影响，而如果直接调用模型进行训练，由于训练的损失函数不同，导致总的成本过高。 举个例子： 补多 补少 实际成本 4 3 1 1 2 1 3 4 1 3 5 1 2 1 50 如果忽略了补多成本和补少成本，可能全部预测为10（均值），得到的总成本为139。当预测为1的时候，总成本为49，所以能得到更好的结果。 思路方案： GBDT中，对于每个树节点的样本集合，其预测值为样本观察值的均值（如果有权重则是加权平均），如果考虑补多成本以及补少成本，可以有以下一个结论： 样本集合的最优预测值为某个样本的观察值。 因为当预测值不属于某个样本的观察值，由于损失函数中样本的观察值和预测值之差是线性关系。设观察值大于预测值的样本补少成本总和为a，观察值大于观测值的样本补多成本总和为b，当a&lt;&gt;b时，预测值减少或者增大时能取得更少的成本；当a=b时，预测值减少或增大一点点并不影响成本。因此，当预测值为某个样本的观察值时，预测值增大或者减少会影响补多成本总和a和补少成本总和b的改变，成本才达到最小值。 所以GBDT树节点中，枚举某个特征值把样本集合划分为两个子集，每个样本子集选取某个样本观察值作为最优预测值，计算减少的成本，最终枚举得到最优的特征值使得成本最小。因此针对某个特征列，有以下几个思路去求解划分样本的最优特征集。 枚举计算 枚举划分的特征值，对于划分的两个样本子集遍历计算成本。时间复杂度为$O(n^2)$，样本数量多的时候会耗时过大。 平衡树 样本集按照特征值从小到大枚举，划分的两个样本子集是一个不断增加样本，另一个不断减少样本。每个样本子集可以维护一棵平衡树，平衡树的按照样本的观察值排序，每个树节点存储子树的补多成本、补少成本和、样本观察值总和，可以从平衡树的根节点向下递推得到最优的观测值（左儿子的样本观察值或者右儿子的样本观察值作为预测值，分别计算成本，选取最优的向下递推，最终到达树儿子节点的样本观察值为预测值）。平衡树的维护和查询时间复杂度为$O(log(n))$，所以总时间复杂度为$O(nlog(n))$。但是编程的难度相对会提升很大。 链表 主要是在枚举特征值的时候，动态的维护两个样本子集，并且能够迅速的得到最优预测值。这里主要讨论样本子集不断减少样本的，因为增加样本的也就相当于反向枚举然后不断减少样本。 假设存在5个样本，按照观察值从小到大排列并建立链表（链表的作用是为了动态维护样本之间的有序性）。可以得出最优预测值为3，成本为15。现从小到大枚举特征值，删除对应的样本并且计算其成本。 补多成本 补少成本 特征值 观察值 2 3 2 1 3 2 4 2 2 1 3 3 1 2 5 4 4 3 1 5 删除特征值1的样本： 补多成本 补少成本 特征值 观察值 2 3 2 1 3 2 4 2 2 1 3 3 1 2 5 4 当预测值为原来的3时，成本是9。而最优预测值为2，成本是7。这是因为删除的样本会减少补少成本总和b，对应的预测值可以适当减少平衡补少成本总和以及补多成本总和使得总成本变小。相应的，如果删除的样本减少补多成本总和a，可以适当的增加预测值。预测值的变化只需要沿着链表遍历动态维护成本的变化即可。 通过这种方法可以求得各个划分的样本子集的最预测值和对应成本，即可求得最优划分特征值。最坏的时间复杂度为$O(n^2)$，每次动态维护成本变化时候都遍历整个链表。事实上在大数据中，平均的复杂度可以达到$O(n)$。 总结 通过修改损失函数的方法，要比GBDT、XGBOOST等单模型结果好很多。但在这次比赛中是不够的，而且平台限制，对于迭代操作并不友好。]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>菜鸟</tag>
        <tag>预测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最后一公里极速配送]]></title>
    <url>%2F2016%2F09%2F22%2F%E6%9C%80%E5%90%8E%E4%B8%80%E5%85%AC%E9%87%8C%E6%9E%81%E9%80%9F%E9%85%8D%E9%80%81%2F</url>
    <content type="text"><![CDATA[题目描述https://tianchi.shuju.aliyun.com/competition/information.htm?spm=5176.100067.5678.2.nXeJox&amp;raceId=231581最后一公里极速配送大赛主要针对赛题背景中提到的电商包裹和同城O2O包裹提供最优的快递员配送方案，快递员需要在指定时间去商户提取并在指定时间内配送至消费者。 成绩第一赛季：第一名第二赛季：第五名（前三名使用了作弊…） 总纲题目中有两种包裹，分别是电商包裹和O2O包裹： 电商包裹：数量多，包裹数目大，路程较近，由124个网点配送； O2O包裹：数量较少，包裹数目小，路程较远，有时间窗口。 由于两种包裹的特性差异较大，如果对所有包裹一起考虑，很难得到一个满意的策略来对问题全局优化。所以在本方案中，两种包裹进行分开考虑，再对每种包裹的方案进行合并。总的方案流程图如下： O2O包裹之费用流在问题中，O2O包裹有配送时间和送达时间的限制，为了简化问题，使得问题更容易求解，有以下假设： 快递员在商家取一个O2O包裹后，下一个动作必定是把包裹送达用户手中。即快递员身上不同时存在两个O2O包裹； 快递员抵达商家的时间，不大于商家要求的取件的时间或超过的时间有个上限值。 基于假设，可以认为快递员在商家要求的区间时间收取O2O包裹，并且立即运送到相应的用户，与原问题相比少了时间窗口限制和容量的限制，容易得到的数学模型表达如下： 设n是O2O包裹数量，m是配送的快递员数量， 表示第i个O2O包裹， 表示第i个O2O包裹的取件时间。相关二进制变量如下：$$g_{ij}=\begin{cases}1&amp; 派送包裹i后派送包裹j\\0&amp; 其它情况\end{cases}$$ 最小化目标函数：$$\mathop {\min }f=\sum_{i=0}^n\sum_{j=0}^ng_{ij}*cost(x_i,x_j)+\sum_{i=0}^nhandle(x_i)$$ s.t.$$\left|\left\{j \left.\right| \sum_{i=0}^ng_{ij}=0 \right\}\right|=m$$$$\sum_{j=0}^ng_{ij}\leq1\ and\ g_{ij}=0\ i\in[0,n)$$ $cost$是根据题目计算的两个O2O包裹间路程的耗时，$handle$是配送O2O包裹的耗时，容易得出公式的第二项是一个常数。 对于问题的求解，容易得出一个费用流的求解方法，有两个参数分别是派送的快递员数量$m$和时间差$tl$： 图中有一个起始顶点$S$和终止顶点$T$； 图中有一个顶点$A$，限制派送包裹的快递员数量，起始点$S$与顶点$A$中有一条容量为m费用为0的弧； 每个包裹对应有两个顶点$B_i$和$C_i$，顶点$B_i$和$C_i$之间有一条容量为1费用为$10000-handle(x_i)$的弧，用来保证每个包裹只被派送一次，而费用加上一个很大的常数10000是为了保证每个包裹都被派送，每个包裹都加上相同的常数并不影响最小化目标函数的求解，$handle(x_i)$是派送包裹的耗时； 当包裹$i$的取件时间不大于的送达时间$tl$（送达时间是指在取件时间开始派送包裹$j$，送到用户的时间），$C_i$和$B_i$之间有一条容量为1费用为从包裹i用户赶往包裹$j$商户的路上耗时。参数tl是为了有效的减少图的规模，并且在图中每个包裹只考虑了上一个包裹是从取件时间开始派送的，忽略了超时的可能性，适当的允许超时在$tl$范围内能够取得更好的结果。 顶点$C_i$和终止顶点$T$之间有一条容量为1费用为0的弧。 最后通过最大费用流的求解即可获得O2O包裹的配送方案，具体的示意图如图所示： O2O包裹之动态规划合并通过费用流得出的O2O包裹配送方案，耗时较大，主要有以下原因： O2O的包裹较小，且路程较远，费用流的方法不能有效的利用快递员的运载量； O2O包裹的配送时限为90分钟，不需要立即送达，可以顺路配送相关的包裹。 所以，需要一种方案来尽量的合并O2O包裹减少耗时。 假设派送O2O包裹可以用序列$a_1,a_2,……,a_r$来表示，例如:派送一个O2O包裹E0000可以表示为E0000:1,E0000:-1，其中1代表取货，-1代表送达，序列表示取包裹E0000然后配送；派送包裹E0000和E0001的可能序列为E0000:1,E0001:1,E0000:-1,E0001:-1，序列表示取E0000包裹，然后取E0001包裹，依次配送E0000和E0001包裹。 当存在配送序列$a_1,a_2,…,a_r$和配送序列$b_1,b_2,…,b_t$，最少耗时的配送序列$c_1,c_2,…,c_{r+t}$可以通过动态规划进行求解： 假设序列$a_i$和$b_i$在最优配送序列ci中，每个O2O包裹的配送顺序与原序列$a_i$和$b_i$相同，虽然此假设并不严谨但在大多数情况下是符合的，基于此假设能够得到动态规划快速求解的方法。 设$f_{i,j,k}$为序列$a_1,a_2,…,a_i$和序列$b_1,b_2,…,b_j$合并为$c_1,c_2,…,c_{i+j}$的最少耗时，其中i≤r，j≤t，k=0或1代表最后一个动作$c_{i+j}$为$a_i$或$b_j$。 $$ \mathop {\min }f_{i,j,k}=\mathop {\min }\begin{cases}min(f_{i-1,j,0}+cost(a_{i-1},a_i),f_{i-1,j,1}+cost(a_j,a_i))&amp; k=0\ and\ i\neq0\\min(f_{i,j-1,0}+cost(a_i,a_j),f_{i,j-1,1}+cost(a_{j-1},a_j))&amp; k=1\ and\ j\neq0\\cost(b_0,…,b_j)+cost(b_j,a_0)&amp; k=0\ and\ i=0\\cost(a_0,…,a_i)+cost(a_i,b_0)&amp; k=1\ and\ j=0\end{cases} $$ 计算过程中$f_{i,j,k}$需要判断序列的包裹合法和相应的路程时间。由此可以得到一个有效的贪心策略： 假设参数$t$； 选取两个包裹a和b，计算$cost(a^b)-cost(a)-cost(b)$，选取$cost$增加最少且增加的$cost&lt;t$的两个包裹进行合并为新的包裹； 当任意两个包裹合并增加的$cost&gt;t$结束，否则从步骤2开始进行。此策略能够有效的合并O2O包裹，提交的方案中选取15，O2O包裹最终的数量&lt;1000。最后通过费用流的方法进行最后的包裹配送规划。 电商包裹之初始化 问题中，电商包裹又124个网点进行配送，且124个网点配送的范围并不重叠。所以不同网点的电商包裹分开考虑，同时也为了减少时间的复杂度。 对于不同网点的包裹配送方案初始化如下: 假设所有的电商包裹都是单独配送并且返回网点。选取任意两个电商包裹一起配送，时间消耗减少了网点分别配送两个包裹的路程耗时，时间消耗增加了两个包裹配送点之间的路程耗时。选取减少消耗最多且满足快递员容量限制的两个包裹一起配送。直至没有包裹可以一起配送为止。 电商包裹之遗传算法 通过遗传算法能够一定程度上减少电商包裹的耗时，但相对于整个算法并不那么重要。遗传算法中加入初始化的结果作为某一条基因组，是为了结果能够更快的收敛。 编码方式：长度为n的编码，每一位记录下一个运送的电商包裹的编号，-1记录返回网点； 适应度函数：cost(电商包裹)； 选择函数：1/适应度； 基因交叉：选择两条基因组，随机选择基因第i位交叉。由于要满足每个电商包裹只能配送一次，基因组中可能存在第j位与第i位是同样的数值，继续在第j位进行交叉，直至基因组合法为止； 基因突变：随机选取某一位设为-1。 电商包裹之局部搜索 通过局部搜索的方法，相比遗传算法能更快更好的减少电商包裹的耗时，但是在电商包裹和O2O包裹合并的过程中没有得到一个很好的结果。所以最终是采用遗传算法。 所有的包裹按照初始化，可以按照配送的顺序排成一行 ，相应的最小耗时可以用动态规划来计算。枚举$i,j$，把$a_i$插入到序列的第$j$位，计算相应的耗时。选取最小耗时的序列保存下来，重复插入的操作直至耗时不能减少为止。 序列$a_i$的最小耗时计算如下： 设$f_i$记录$cost(a_1,a_2,…,a_i)$的最小耗时，状态转移如下：$f_i=min{f_j+cost(a_j,a_{j+1},…,a_i)|j&lt;i,\sum_{k=i}^jpac_k\le140}$，即枚举第$j$到$i$的电商包裹作为连续配送的一个子序列。 背包合并 当O2O包裹合并以后，依然会有取货时间前的一段时间可以配送电商包裹，电商包裹经过合并之后得到了多个包裹的配送序列。所以主要是在配送O2O包裹前选择适合的电商包裹序列配送。 假设配送O2O包裹的起始时间为$st_i$，电商包裹配送序列的耗时为$c_i$，算法的流程如下： 枚举每个O2O包裹$y_i$，起始时间为$st_i$； 枚举电商包裹配送序列$x_i$所谓配送O2O包裹前最后配送的电商包裹； 剩余时间$t=st_i+cost(x_i,y_i)$，cost代表配送完电商包裹然后配送O2O包裹的路程耗时，减去配送完电商包裹返回网点的耗时； 对剩余时间t进行网点与 相同的电商包裹序列填充，这里可以用01背包。但是考虑到有些快递员只配送电商包裹，所以考虑每个电商包裹序列的价值为:电商包裹序列耗时-网点到最后一个配送点的路上耗时，能够获得更好的方案。 删除所有选择的电商包裹序列； 重复以上步骤，直至枚举所有的O2O包裹。 对剩余的O2O包裹用空闲的快递员进行配送 尝试比赛中有各种尝试： 费用流中加入预测评估使得O2O包裹的起始时间能更好的合并电商包裹 O2O包裹和电商包裹在DP Merge中一起合并 各种尝试中会增加算法的复杂度，但是提高的成绩并不明显，因此也不再描述了。 总结 总的来说，方案中采用的是O2O包裹和电商包裹分开的计算的方法。O2O包裹合并之后能够有效的对O2O包裹进行配送。我认为本方案的优点在于：算法运行的速度快，能够很快的得出结果，思路也是比较的简单的。而方案中比较不足的在于：O2O包裹和电商包裹不能很好的进行融合，而且在单独配送电商包裹的策略中没有很好的考虑O2O包裹的取件时间。 在后面经过对方案的统计分析，即使把方案中的电商包裹策略做的更加完善也不能提高很多，因此后面的工作主要着重于如何真正的把电商包裹和O2O包裹融合起来。但是考虑到时间复杂度等问题，最终没有得到一个很好的解决方案，不能不是一个遗憾。 答辩总结 比赛中第一赛季第一名，第二赛季第五名。在第二赛季中有意思的是在最后几天不断被反超了，而且分数的差距非常大，所以答辩也是抱着学习的心态去的。 但是前三名的成绩是利用了题目10次作弊的限制，而且官方的评测程序计算耗时是根据提交结果的上一个时间计算，所以快递员配送过程中10次瞬移能得到更好的结果（第一赛季没多大用，第二赛季很多超时的O2O包裹所以提升会非常大）。其实这是很不合理的，但是阿里默认这种解释，即使不爽也没办法的了。 答辩过程中也能看到些其它的方法，也有所启发吧，不过毕竟不是研究这领域的，也不打算研究下去了。]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>最后一公里</tag>
        <tag>o2o</tag>
        <tag>费用流</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
</search>
